---
title: "R for developers"
author: "Steph Locke"
date: "`r Sys.Date()`"
output:
  Rtraining::stephSlideStyle:
    css: NULL
  beamer_presentation:
    template: default.tex
    theme: m
    pandoc_args: [
      "--latex-engine=xelatex"
    ]
---

## Steph Locke | Who I am

- Data specialist
- Principal Consultant \@ Mango Solutions
- github: [stephlocke/Rtraining](http://github.com/stephlocke/Rtraining)
- blog: [itsalocke.com](http://itsalocke.com)
- t: [\@stefflocke](http://twitter.com/stefflocke)

# R

## R | A brief history
- S, born 1976 in Bell Laboratories
- R, born 1997 in a uni in NZ
- R Foundation, born 2002
- R Consortium, born 2015
- R now ranked 6th most popular language by IEEE

## R | Why use it?
- For the stats
- For the cross-platform capability
- For the reproducibility
- For the time it can save
- For the flexibility
- For the money

## R | Why not Python?
Firstly, Python is a valid way to go. There are number of really good libraries out there for number crunching etc. and it is a well written language with few "quirks"

Secondly, why R is my preference:

- Easy install
- Strong community base
- Data focused
- Very flexible and extendable
- It's the favourite to win

But... "production" code can be faster in Python 

# R fundamentals
## Basics
```{r}
# Define a variable
a<-25

# Call a variable
a

# Do something to it
a+1
```

## Data types | p1
```{r}
# Numeric
25

# Character
"25"

# Logical
TRUE
```

## Data types | p2
```{r}
# Dates
as.Date("2015-08-05")
as.POSIXct("2015-08-01")
```

## Data types | p3
```{r}
# Factor
as.numeric(factor("25"))
as.character(factor("25"))
```

## Constructs | p1
```{r}
# Vector
a<-c(25, 30)

# Matrix
matrix(a)
```

## Constructs | p2
```{r}
# Data frame
data.frame(a,b=a/5,c=LETTERS[1:2])

# List
list(vector=a, matrix=matrix(a))
```

## Subsetting | Vectors
```{r}
a <- sample(1:20, size = 5, replace = TRUE) # setup
a # visual check
a[1:2] # row numbers
a[a<=10] # value filters
```

## Subsetting | Data.frames p1
```{r}
df <- data.frame(a=1:10, b = LETTERS[1:5]) # setup
df[1:2,] # row numbers
df[df$a<2,] # value filters
```

## Subsetting | Data.frames p2
```{r}
df[df$a<3,1] # column filter
df[df$a<3,1, drop=FALSE] # column filter (keep data.frame)
```

## Functions
```{r}
# Define a function
showAsPercent<-function(x) {
  paste0(round(x*100 ,0) ,"%")
}

# Call a function
showAsPercent(0.1)
```

## Extending R
```{r, eval=FALSE }
# Get a package
install.packages("caret")

# Activate a package
library(caret)
```


## What does R look like? | OO
```{r, results='hide', echo=FALSE, warning=FALSE, message=FALSE}
library("R6")
```

```{r}
# Orig OO (s3): cyclismo.org/tutorial/R/s3Classes.html
library(R6)
Loan<-R6Class("Loan", 
              public=list(term=NA
                         ,initialize=function(term){
                           if(!missing(term)){ 
                              self$term<-term 
                              }} 
                         ,extendBy=function(ext){ 
                            self$term<-self$term+ext
                            }))
```

## What does R look like? | OO
```{r}
acc<-Loan$new(36)
acc$extendBy(6)
acc$term
```


# Building up an R script

## Commands | magrittr
magrittr allows you to pass one thing into another instead of writing lots of brackets
```{r, results='hide', echo=FALSE, warning=FALSE, message=FALSE}
library(magrittr)
```

```{r, results='hide', eval=FALSE}
library(magrittr)
# Typical
pairs(iris)
pairs(tail(iris))
pairs(tail(iris,nrow(iris)/5))

# Pipe
iris %>% pairs
iris %>% tail %>% pairs
iris %>% {tail(.,nrow(.)/5)} %>% pairs
```

## Commands | dplyr
Use `dplyr` to transform your datasets

```{r, results='hide', echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(magrittr)
```

```{r}
library(dplyr)
iris %>% 
  filter(Petal.Width<2) %>%
  group_by(Species) %>%
  summarise_each(funs(mean))
```

## Read data | CSV & Excel
```{r, eval=FALSE}
library(readr)
OrderData<-read_csv("Order.csv")

library(readxl)
OrderData<-read_sheet("Order.xlsx","Orders")
```

## Read data | Databases
```{r, eval=FALSE}
library(RODBC)
azure <- odbcDriverConnect(
  "Driver={SQL Server Native Client 11.0};
  Server=mhknbn2kdz.database.windows.net;
  Database=AdventureWorks2012;
  Uid=sqlfamily;
  Pwd=sqlf@m1ly;")

Order    <- sqlQuery( azure, 
            "SELECT * FROM [Sales].[SalesOrderHeader]")
```

## Write data | CSV
This is easiest and most portable option
```{r, eval=FALSE}
write.csv(iris,"iris.csv", row.names = FALSE)
```

## Script best practices
- Make sure to declare packages using `library()` at the top of the script
- Label sections of work using `# ---- SectionName ----` to allow you to pick up the code into a LaTeX or markdown doc later
- Never delete <- always make new objects with modifications
- If comfortable with coding, or have a lot of data to process use `data.table` over `dplyr`
- Try to do all data manipulation at the top of the script
- Reuse your code by writing functions for anything you do frequently

<!--
# Apply some models to your data

## Some common models
```{r, eval=FALSE}
# linear models (inc. logistic)
glm(data=iris, Sepal.Width~Sepal.Length)

# k-means clustering
kmeans(iris[,1:4],centers = 3)
```

## Sampling
```{r, eval=FALSE}
library(caret)
sampleRecords<-createDataPartition(iris$Species
                                   , groups = 2, p = 0.7)$Resample1
irisTraining<-iris[sampleRecords,]
irisHoldout<-iris[-sampleRecords,]
```

## Extracting predictions
```{r, eval=FALSE}
# linear models (inc. logistic)
myModel<-glm(data=irisTraining, Sepal.Width~Sepal.Length)

# predictions for training sample
myModel$fitted.values

# predictions for a new set of data
predict(myModel,irisHoldout)
```

## More info
- There is a lot of documentation out there on stats in R
- Use [Cross Validated](http://stats.stackexchange.com/) for stats questions
- The package `caret` is really powerful and provides an interface to lots of statistical methods and utilities.
-->

# "Best" practices

## Charts
```{r, echo=TRUE,eval=TRUE, fig.height=4}
library(ggplot2)
ggplot(data=iris, 
       aes(x=Sepal.Width, y=Sepal.Length, colour=Species)) + 
  geom_point() 
```

## Documentation
Document as you go!

- Use markdown to use a light syntax for integrating your code and commentary
- Use LaTeX for finer level of control on output layout
- Use these instead of Excel or Word so that a change in assumption means updating the code and re-running the doc
- Load your main R file up and use the labels from `# ---- SectionName ----` to save repetition
- Present in HTML, slide decks, PDF, Word at the click of a button

## Interactive reports
Consider doing a `shiny` application that explores the data and findings


## Workflow best practices
- Focus on working code & documentation
- Use source control (github)
- Write tests (`assertive`, `assertthat`, `testthat`)
- Regularly visualise (`ggplot2`)
- Do code reviews
- Modularise
- Use Rstudio
- Consider structuring as a package

# Next steps
## Find out more

### Online
- Modern R [DataCamp](http://datacamp.com) 
- Statistics R [Coursera](https://www.coursera.org/specialization/jhudatascience) 
- [R-bloggers](http://www.r-bloggers.com/) 
- [Advanced R programming](http://adv-r.had.co.nz/)
- [Writing R packages](http://r-pkgs.had.co.nz/)


### In-person
- R user groups e.g. [LondonR](http://www.londonr.org/)
- Conferences e.g. [EARL](http://www.earl-conference.com/), [SQL Relay](http://sqlrelay.co.uk)


## Get this presentation
This presentation is available on [github.com/stephlocke/Rtraining](https://github.com/stephlocke/Rtraining). All the code is available for you to take a copy and play with to help you learn on the go.

If you have any questions, contact me! 

[itsalocke.com](http://itsalocke.com) | [github.com/StephLocke](https://github.com/StephLocke) | [\@SteffLocke](https://twitter.com/stefflocke)